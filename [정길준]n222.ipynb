{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "[정길준]n222",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gilbert9172/CSAI_assignment/blob/main/%5B%EC%A0%95%EA%B8%B8%EC%A4%80%5Dn222.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# 1) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW8VbuppViAV",
        "outputId": "43ee40a4-5671-4f61-bc39-c79766cc817f"
      },
      "source": [
        "pip install --upgrade category_encoders"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td5prwgifGME"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "target = 'vacc_h1n1_f'\n",
        "\n",
        "train_data = pd.merge(pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train.csv'), \n",
        "                 pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train_labels.csv')[target], left_index=True, right_index=True)\n",
        "test = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q_g0TetfNPM",
        "outputId": "cf3ea34f-c543-4acd-cf8a-056322d754a5"
      },
      "source": [
        "# opinion_h1n1_vacc_effective; 벡신접종 후 영향에  대한의견이 순서형 범주에 해당\n",
        "train_data['opinion_h1n1_vacc_effective'].value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Somewhat Effective      14729\n",
              "Very Effective           9052\n",
              "Dont Know                6033\n",
              "Not Very Effective       2312\n",
              "Not At All Effective     1111\n",
              "Refused                   138\n",
              "Name: opinion_h1n1_vacc_effective, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVjideYMfOxU"
      },
      "source": [
        "# OrdinalEncoder 인코딩\n",
        "# from category_encoders import OrdinalEncoder \n",
        "\n",
        "# Ord_enc = OrdinalEncoder(handle_missing=\"value\")\n",
        "\n",
        "# enc = {\"Dont Know\":0, \"Refused\": 1, \"Not At All Effective\": 2, \"Not Very Effective\": 3, \"Somewhat Effective \":4,\"Very Effective\":5}\n",
        "\n",
        "# train_data['opinion_h1n1_vacc_effective'] = train_data.opinion_h1n1_vacc_effective.map(enc)\n",
        "\n",
        "# # NaN값 = 0 : Dont Know\n",
        "# train_data['opinion_h1n1_vacc_effective'] = train_data['opinion_h1n1_vacc_effective'].fillna(0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MAURvohEznM"
      },
      "source": [
        "train, val = train_test_split(train_data, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train_data[target], random_state=2)\n",
        "def engineer(df):\n",
        "    selected_cols = df.select_dtypes(include=['number', 'object'])\n",
        "    labels = selected_cols.nunique() \n",
        "    selected_features = labels[labels <= 30].index.tolist() \n",
        "    df = df[selected_features]\n",
        "\n",
        "    df.drop(['employment_industry','employment_occupation'], axis = 1, inplace=True)    \n",
        "    return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2gvGmjoVR76"
      },
      "source": [
        "features = train.drop(columns=[target]).columns\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "X_test = test[features]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpaUTAsHEznM"
      },
      "source": [
        "# 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2rtOyS8JaKt"
      },
      "source": [
        "# 연습 (문제점 : 너무 느리다. 나무 성장과정 보는 수준)\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.impute import SimpleImputer  \n",
        "# from sklearn.pipeline import make_pipeline\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# pipe_ord = make_pipeline(\n",
        "#     OrdinalEncoder(),\n",
        "#     SimpleImputer(strategy = 'median'),\n",
        "#     RandomForestClassifier(random_state = 0, \n",
        "#                            n_jobs = -1, \n",
        "#                            oob_score = True)\n",
        "# )"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLYkmlgLL5Xh"
      },
      "source": [
        "# sorted(pipe_ord.get_params().keys())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVv7qNDYKnjU"
      },
      "source": [
        "# param_grid = {\n",
        "#     'randomforestclassifier__n_estimators': [100,200],\n",
        "#     'randomforestclassifier__max_depth': [6,8,10,12],\n",
        "#     'randomforestclassifier__min_samples_leaf': [2,6,10],\n",
        "#     'randomforestclassifier__min_samples_split' : [2,4,6,8]\n",
        "# }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5tM8-boK81k"
      },
      "source": [
        "# rf_grid = GridSearchCV(pipe_ord,param_grid=param_grid,scoring=\"accuracy\",\n",
        "#                        n_jobs = -1, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDj51oFQLTSL"
      },
      "source": [
        "# rf_grid.fit(X_train,y_train)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1hQOuy5U-K0"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
        "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
        "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.0min\n",
        "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  9.1min\n",
        "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed: 23.8min\n",
        "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 26.0min finished\n",
        "GridSearchCV(cv=None, error_score=nan,\n",
        "             estimator=Pipeline(memory=None,\n",
        "                                steps=[('ordinalencoder',\n",
        "                                        OrdinalEncoder(cols=None,\n",
        "                                                       drop_invariant=False,\n",
        "                                                       handle_missing='value',\n",
        "                                                       handle_unknown='value',\n",
        "                                                       mapping=None,\n",
        "                                                       return_df=True,\n",
        "                                                       verbose=0)),\n",
        "                                       ('simpleimputer',\n",
        "                                        SimpleImputer(add_indicator=False,\n",
        "                                                      copy=True,\n",
        "                                                      fill_value=None,\n",
        "                                                      missing_values=nan,\n",
        "                                                      strategy='median',\n",
        "                                                      verbose=0))...\n",
        "                                                               warm_start=False))],\n",
        "                                verbose=False),\n",
        "             iid='deprecated', n_jobs=-1,\n",
        "             param_grid={'randomforestclassifier__max_depth': [6, 8, 10, 12],\n",
        "                         'randomforestclassifier__min_samples_leaf': [2, 6, 10],\n",
        "                         'randomforestclassifier__min_samples_split': [2, 4, 6,\n",
        "                                                                       8],\n",
        "                         'randomforestclassifier__n_estimators': [100, 200]},\n",
        "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
        "             scoring='accuracy', verbose=1)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovTUQzjfSc7c"
      },
      "source": [
        "# rf_grid.best_params_"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDMKpS8RU0-4"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "{'randomforestclassifier__max_depth': 12,\n",
        " 'randomforestclassifier__min_samples_leaf': 6,\n",
        " 'randomforestclassifier__min_samples_split': 2,\n",
        " 'randomforestclassifier__n_estimators': 100}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ki8hkAIEznM"
      },
      "source": [
        "# RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer  \n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "from category_encoders import OrdinalEncoder \n",
        "\n",
        "pipe_ord = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(strategy = 'mean'),\n",
        "    RandomForestClassifier(n_estimators = 100, \n",
        "                           max_depth=12,\n",
        "                           class_weight='balanced',\n",
        "                           min_samples_split = 2,\n",
        "                           min_samples_leaf = 6,\n",
        "                           random_state = 1, \n",
        "                           n_jobs = -1, \n",
        "                           oob_score = True)\n",
        ")\n",
        "\n",
        "pipe_ord.fit(X_train,y_train)\n",
        "\n",
        "y_v_pred = pipe_ord.predict(X_val)\n",
        "print('학습정확도', pipe_ord.score(X_train,y_train))\n",
        "print('검증정확도', pipe_ord.score(X_val,y_val))\n",
        "print('F1_Score', f1_score(y_val, y_v_pred))\n",
        "\n",
        "# 학습정확도 0.8337040002372268\n",
        "# 검증정확도 0.800260941762543\n",
        "# F1_Score 0.6308636562911004"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjz4e0aZncEZ"
      },
      "source": [
        "# 연습 : ExtraTreesClassifier ()\n",
        "# from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "# pipe_ord = make_pipeline(\n",
        "#     OrdinalEncoder(),\n",
        "#     SimpleImputer(strategy = 'mean'),\n",
        "#     ExtraTreesClassifier(n_estimators = 100, \n",
        "#                            bootstrap=True,\n",
        "#                            max_depth=12,\n",
        "#                            class_weight='balanced',\n",
        "#                            min_samples_split = 2,\n",
        "#                            min_samples_leaf = 6,\n",
        "#                            random_state = 1, \n",
        "#                            n_jobs = -1, \n",
        "#                            oob_score = True)\n",
        "# )\n",
        "\n",
        "# pipe_ord.fit(X_train,y_train)\n",
        "\n",
        "# y_v_pred = pipe_ord.predict(X_val)\n",
        "# print('학습정확도', pipe_ord.score(X_train,y_train))\n",
        "# print('검증정확도', pipe_ord.score(X_val,y_val))\n",
        "# print('F1_Score', f1_score(y_val, y_v_pred))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbEG8TS3EznN"
      },
      "source": [
        "\n",
        "#3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCH-AVQcWPVE"
      },
      "source": [
        "- Target encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0p7IidmaTZk"
      },
      "source": [
        "RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer  \n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "\n",
        "pipe_ord = make_pipeline(\n",
        "    TargetEncoder(),\n",
        "    SimpleImputer(strategy = 'mean'),\n",
        "    RandomForestClassifier(n_estimators = 100, \n",
        "                           max_depth=12,\n",
        "                           class_weight='balanced',\n",
        "                           min_samples_split = 2,\n",
        "                           min_samples_leaf = 5,\n",
        "                           random_state = 1, \n",
        "                           n_jobs = -1, \n",
        "                           oob_score = True)\n",
        ")\n",
        "pipe_ord.fit(X_train,y_train)\n",
        "\n",
        "y_v_pred = pipe_ord.predict(X_val)\n",
        "print('학습정확도', pipe_ord.score(X_train,y_train))\n",
        "print('검증정확도', pipe_ord.score(X_val,y_val))\n",
        "print('F1_Score', f1_score(y_val, y_v_pred))\n",
        "\n",
        "# 학습정확도 0.8383892299024405\n",
        "# 검증정확도 0.8070217056102479\n",
        "# F1_Score 0.6407595495694414"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UPgjOF46aKM"
      },
      "source": [
        "y_predict = pipe_ord.predict(X_test)\n",
        "\n",
        "sample_submission = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/submission.csv')\n",
        "\n",
        "sample_submission['vacc_h1n1_f'] = y_predict\n",
        "\n",
        "sample_submission = sample_submission.set_index('Id')\n",
        "\n",
        "sample_submission"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY1L-bMvpSZJ"
      },
      "source": [
        "# sample_submission.to_csv('submission_g.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etuHJPx6czyF"
      },
      "source": [
        "[Target encoding (번역)](https://brendanhasz.github.io/2019/03/04/target-encoding#target-encoding)\n",
        "\n",
        "```\n",
        "원핫인코딩의 문제점은, 학습데이터의 차원을 아주 많이 증가시킨다는 점입니다.\n",
        "\n",
        "이 문제는 종종 모델의 성능을 저하 시키고, 차원의 저주에 빠지게 합니다. \n",
        "\n",
        "반면에 타겟 인코딩은 우리가 좋은 정보를 얻을 수 있게 유용한 카테고리를 유지시켜 줍니다.\n",
        "\n",
        "(이 부분에서 원핫인코딩과 비슷하지만, 라벨 인코딩과는 사뭇 다른 느낌입니다. )\n",
        "\n",
        "동시에 타겟인코딩은 인코딩 전의 차원을 그대로 유지 시켜줍니다.\n",
        "\n",
        "(이 부분에서는 라벨인코딩과 비슷하고, 원핫인코딩과 차이가 납니다.)\n",
        "\n",
        "각 피쳐의 데이터에 대해서 타겟 인코딩을 하기 위해서는, 각 카테고리를 해당 카테고리 샘플의 평균으로 대체해줍니다.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ]
    }
  ]
}